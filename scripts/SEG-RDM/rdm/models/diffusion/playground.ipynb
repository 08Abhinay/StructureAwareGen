{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f6657c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-17 17:43:57.403571: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1768689837.530048 2992297 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1768689837.564813 2992297 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1768689837.882650 2992297 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768689837.882665 2992297 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768689837.882667 2992297 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768689837.882669 2992297 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2026-01-17 17:43:57.920831: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Matplotlib is building the font cache; this may take a moment.\n",
      "/home/abelde/.local/lib/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n",
      "  backends.update(_get_backends(\"networkx.backends\"))\n",
      "/home/abelde/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m     sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, repo_root)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# If you already imported these in the notebook, reload to pick up edits/breakpoints\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmain_rdm\u001b[39;00m\n\u001b[1;32m     21\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(main_rdm)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# # -----------------------------\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# # Debug tip:\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# # For notebook debugging, DON'T use torch.distributed.launch.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m#     import runpy\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m#     runpy.run_path(os.path.join(repo_root, \"main_rdm.py\"), run_name=\"__main__\")\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/gilbreth/abelde/Thesis/StructureAwareGen/scripts/rcg/main_rdm.py:17\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtimm\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m timm\u001b[38;5;241m.\u001b[39m__version__ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.3.2\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# version check\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmisc\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NativeScalerWithGradNormCount \u001b[38;5;28;01mas\u001b[39;00m NativeScaler\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "# -----------------------------\n",
    "# Paths (edit if needed)\n",
    "# -----------------------------\n",
    "repo_root = \"/scratch/gilbreth/abelde/Thesis/StructureAwareGen/scripts/rcg\"\n",
    "config_path = \"config/rdm/mocov3vitb_simplemlp_l12_w1536.yaml\"  # relative to repo_root is fine\n",
    "output_dir = os.environ.get(\"OUTPUT_DIR\", \"/scratch/gilbreth/abelde/rdm_debug_out\")\n",
    "imagenet_dir = os.environ.get(\"IMAGENET_DIR\", \"/scratch/gilbreth/abelde/datasets/imagenet\")\n",
    "\n",
    "# -----------------------------\n",
    "# Put repo on import path\n",
    "# -----------------------------\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.insert(0, repo_root)\n",
    "\n",
    "# If you already imported these in the notebook, reload to pick up edits/breakpoints\n",
    "import main_rdm\n",
    "importlib.reload(main_rdm)\n",
    "\n",
    "# # -----------------------------\n",
    "# # Debug tip:\n",
    "# # For notebook debugging, DON'T use torch.distributed.launch.\n",
    "# # Run single GPU / single process. That means:\n",
    "# #   - remove/ignore --dist_url / --nnodes / --node_rank / --nproc_per_node\n",
    "# # -----------------------------\n",
    "# sys.argv = [\n",
    "#     \"main_rdm.py\",\n",
    "#     \"--config\", config_path,\n",
    "#     \"--batch_size\", \"128\",\n",
    "#     \"--input_size\", \"256\",\n",
    "#     \"--epochs\", \"200\",\n",
    "#     \"--blr\", \"1e-6\",\n",
    "#     \"--weight_decay\", \"0.01\",\n",
    "#     \"--output_dir\", output_dir,\n",
    "#     \"--data_path\", imagenet_dir,\n",
    "\n",
    "#     # Optional: make sure it doesn't try multi-process\n",
    "#     # (one of these usually exists; keep only the ones your argparse supports)\n",
    "#     \"--world_size\", \"1\",\n",
    "#     \"--local_rank\", \"0\",\n",
    "# ]\n",
    "\n",
    "# # -----------------------------\n",
    "# # Run\n",
    "# # -----------------------------\n",
    "# # Many repos have main() defined; if not, they run under `if __name__ == \"__main__\":`\n",
    "# # We'll try main() first.\n",
    "# if hasattr(main_rdm, \"main\"):\n",
    "#     main_rdm.main()\n",
    "# else:\n",
    "#     # fallback: execute the file as a script\n",
    "#     import runpy\n",
    "#     runpy.run_path(os.path.join(repo_root, \"main_rdm.py\"), run_name=\"__main__\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58647c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.9.23\n",
      "Executable: /scratch/gilbreth/abelde/Thesis/StructureAwareGen/SegmentationAwareGen/bin/python\n",
      "\n",
      "=== Package versions (pip/metadata + import fallback) ===\n",
      "python             -> 3.9.23\n",
      "pip                -> 25.3\n",
      "cudatoolkit        -> NOT INSTALLED\n",
      "pytorch            -> 2.7.0+cu126 | cuda=12.6 | torch.cuda.is_available()=True\n",
      "torchvision        -> 0.22.0\n",
      "numpy              -> 1.20.3\n",
      "albumentations     -> NOT INSTALLED\n",
      "opencv-python      -> 4.12.0\n",
      "pudb               -> NOT INSTALLED\n",
      "imageio            -> 2.37.0\n",
      "imageio-ffmpeg     -> 0.4.3\n",
      "pytorch-lightning  -> 2.5.1.post0\n",
      "torchmetrics       -> 1.7.2\n",
      "setuptools         -> 80.9.0\n",
      "omegaconf          -> 2.3.0\n",
      "test-tube          -> NOT INSTALLED\n",
      "streamlit          -> NOT INSTALLED\n",
      "einops             -> 0.8.1\n",
      "more-itertools     -> 10.3.0\n",
      "timm               -> 1.0.15\n",
      "protobuf           -> 5.29.4\n",
      "submitit           -> NOT INSTALLED\n",
      "diffusers          -> NOT INSTALLED\n",
      "accelerate         -> 1.6.0\n",
      "huggingface-hub    -> 0.30.2\n",
      "transformers       -> 4.51.3\n",
      "torch-fidelity     -> NOT INSTALLED\n",
      "clip               -> NOT INSTALLED\n",
      "taming-transformers -> NOT INSTALLED\n",
      "rcg                -> NOT INSTALLED\n",
      "\n",
      "=== GPU / Torch details (if torch installed) ===\n",
      "torch: 2.7.0+cu126\n",
      "torch.version.cuda: 12.6\n",
      "torch.backends.cudnn.version(): 90501\n",
      "cuda available: True\n",
      "device count: 1\n",
      "device 0: NVIDIA A30\n",
      "\n",
      "=== Conda list (filtered) if conda exists ===\n",
      "conda not available in this kernel (that's okay): [Errno 2] No such file or directory: 'conda'\n"
     ]
    }
   ],
   "source": [
    "# Notebook cell: print versions of packages in your current conda env\n",
    "import sys, subprocess, importlib\n",
    "from importlib.metadata import version as dist_version, PackageNotFoundError\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"Executable:\", sys.executable)\n",
    "print()\n",
    "\n",
    "# Map pip/distribution names -> import names (when different)\n",
    "PKGS = [\n",
    "    (\"python\", None),\n",
    "    (\"pip\", None),\n",
    "    (\"cudatoolkit\", None),          # conda package; we'll show via `conda list` if available\n",
    "    (\"pytorch\", \"torch\"),\n",
    "    (\"torchvision\", \"torchvision\"),\n",
    "    (\"numpy\", \"numpy\"),\n",
    "    (\"albumentations\", \"albumentations\"),\n",
    "    (\"opencv-python\", \"cv2\"),\n",
    "    (\"pudb\", \"pudb\"),\n",
    "    (\"imageio\", \"imageio\"),\n",
    "    (\"imageio-ffmpeg\", None),       # dist name only\n",
    "    (\"pytorch-lightning\", \"pytorch_lightning\"),\n",
    "    (\"torchmetrics\", \"torchmetrics\"),\n",
    "    (\"setuptools\", \"setuptools\"),\n",
    "    (\"omegaconf\", \"omegaconf\"),\n",
    "    (\"test-tube\", \"test_tube\"),\n",
    "    (\"streamlit\", \"streamlit\"),\n",
    "    (\"einops\", \"einops\"),\n",
    "    (\"more-itertools\", \"more_itertools\"),\n",
    "    (\"timm\", \"timm\"),\n",
    "    (\"protobuf\", \"google.protobuf\"),\n",
    "    (\"submitit\", \"submitit\"),\n",
    "    (\"diffusers\", \"diffusers\"),\n",
    "    (\"accelerate\", \"accelerate\"),\n",
    "    (\"huggingface-hub\", \"huggingface_hub\"),\n",
    "    (\"transformers\", \"transformers\"),\n",
    "    (\"torch-fidelity\", \"torch_fidelity\"),\n",
    "    (\"clip\", \"clip\"),\n",
    "    (\"taming-transformers\", \"taming\"),  # sometimes import is `taming`; if missing we'll still show dist version\n",
    "    (\"rcg\", None),                   # your editable -e . package name might differ; we'll try dist lookup\n",
    "]\n",
    "\n",
    "def get_dist_ver(dist_name: str):\n",
    "    try:\n",
    "        return dist_version(dist_name)\n",
    "    except PackageNotFoundError:\n",
    "        return None\n",
    "\n",
    "def get_import_ver(mod_name: str):\n",
    "    try:\n",
    "        m = importlib.import_module(mod_name)\n",
    "        return getattr(m, \"__version__\", None)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def show_pkg(dist_name, mod_name):\n",
    "    dv = get_dist_ver(dist_name) if dist_name else None\n",
    "    mv = get_import_ver(mod_name) if mod_name else None\n",
    "    v = dv or mv\n",
    "    status = v if v else \"NOT INSTALLED\"\n",
    "    extra = \"\"\n",
    "    if dist_name == \"pytorch\" and \"torch\" in sys.modules:\n",
    "        import torch\n",
    "        extra = f\" | cuda={torch.version.cuda} | torch.cuda.is_available()={torch.cuda.is_available()}\"\n",
    "    print(f\"{dist_name:18s} -> {status}{extra}\")\n",
    "\n",
    "print(\"=== Package versions (pip/metadata + import fallback) ===\")\n",
    "for dist_name, mod_name in PKGS:\n",
    "    if dist_name == \"python\":\n",
    "        print(f\"{'python':18s} -> {sys.version.split()[0]}\")\n",
    "        continue\n",
    "    show_pkg(dist_name, mod_name)\n",
    "\n",
    "print(\"\\n=== GPU / Torch details (if torch installed) ===\")\n",
    "try:\n",
    "    import torch\n",
    "    print(\"torch:\", torch.__version__)\n",
    "    print(\"torch.version.cuda:\", torch.version.cuda)\n",
    "    print(\"torch.backends.cudnn.version():\", torch.backends.cudnn.version())\n",
    "    print(\"cuda available:\", torch.cuda.is_available())\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"device count:\", torch.cuda.device_count())\n",
    "        print(\"device 0:\", torch.cuda.get_device_name(0))\n",
    "except Exception as e:\n",
    "    print(\"torch not usable:\", e)\n",
    "\n",
    "print(\"\\n=== Conda list (filtered) if conda exists ===\")\n",
    "try:\n",
    "    out = subprocess.check_output([\"conda\", \"list\"], text=True)\n",
    "    # filter lines that mention our key packages\n",
    "    keys = [\"python\", \"pip\", \"cudatoolkit\", \"pytorch\", \"torchvision\", \"numpy\"]\n",
    "    for line in out.splitlines():\n",
    "        if any(k in line.split()[:1] for k in keys):\n",
    "            print(line)\n",
    "except Exception as e:\n",
    "    print(\"conda not available in this kernel (that's okay):\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a699d591",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
