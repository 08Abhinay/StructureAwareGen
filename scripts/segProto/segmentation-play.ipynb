{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "796cf4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abelde/.local/lib/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n",
      "  backends.update(_get_backends(\"networkx.backends\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AMG-prod:   0%|          | 0/5 [32:09<?, ?it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, glob, json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "from segment_anything import sam_model_registry,  SamAutomaticMaskGenerator, SamPredictor\n",
    "\n",
    "# =========================\n",
    "# CONFIG (edit these)\n",
    "# =========================\n",
    "IN_DIR = \"/scratch/gilbreth/abelde/Thesis/StructureAwareGen/dataset/val2017\"\n",
    "OUT_ROOT = \"/scratch/gilbreth/abelde/Thesis/StructureAwareGen/scripts/segProto/out_amg_prod-2-trial\"\n",
    "CHECKPOINT = \"/scratch/gilbreth/abelde/Thesis/StructureAwareGen/scripts/segProto/checkpoints/sam_vit_b_01ec64.pth\"\n",
    "MODEL_TYPE = \"vit_b\"       # vit_b / vit_l / vit_h\n",
    "MAX_IMAGES = 5             # -1 for all\n",
    "\n",
    "# AMG \"segment everything\" knobs (balanced)\n",
    "POINTS_PER_SIDE = 64       # 128 is heavier; 256 is often overkill\n",
    "CROP_N_LAYERS = 1          # 0 = no crops, 1-2 helps small objects a lot\n",
    "CROP_OVERLAP_RATIO = 0.35\n",
    "CROP_N_POINTS_DOWNSCALE = 2\n",
    "\n",
    "PRED_IOU_THRESH = 0.80\n",
    "STABILITY_SCORE_THRESH = 0.85\n",
    "BOX_NMS_THRESH = 0.70\n",
    "\n",
    "# OpenCV-free post filter\n",
    "MIN_MASK_REGION_AREA = 300     # raise (500~2000) to remove tiny junk; 0 disables\n",
    "\n",
    "# Post-selection (makes it \"production\")\n",
    "MAX_KEEP = 250                 # final mask bank size per image\n",
    "DEDUP_IOU_THRESH = 0.90        # drop masks that overlap too much with kept ones\n",
    "\n",
    "# Outputs\n",
    "TOP_K_PNG = 25\n",
    "OVERLAY_TOP_K = 15\n",
    "SAVE_MASK_EMB = True           # per-mask SAM embedding (very useful for conditioning)\n",
    "# =========================\n",
    "\n",
    "\n",
    "def load_image_rgb(path: str) -> np.ndarray:\n",
    "    return np.array(Image.open(path).convert(\"RGB\"), dtype=np.uint8)\n",
    "\n",
    "\n",
    "def mask_stats(mask_bool: np.ndarray):\n",
    "    mask_bool = np.asarray(mask_bool, dtype=bool)\n",
    "    ys, xs = np.where(mask_bool)\n",
    "    if xs.size == 0:\n",
    "        return None\n",
    "\n",
    "    h, w = mask_bool.shape\n",
    "    x0, x1 = int(xs.min()), int(xs.max())\n",
    "    y0, y1 = int(ys.min()), int(ys.max())\n",
    "\n",
    "    area_frac = float(mask_bool.mean())\n",
    "    cx = float(xs.mean() / w)\n",
    "    cy = float(ys.mean() / h)\n",
    "\n",
    "    bw = float((x1 - x0 + 1) / w)\n",
    "    bh = float((y1 - y0 + 1) / h)\n",
    "    bbox_area_frac = float(((x1 - x0 + 1) * (y1 - y0 + 1)) / (h * w))\n",
    "\n",
    "    bbox_area_px = max(1, (x1 - x0 + 1) * (y1 - y0 + 1))\n",
    "    fill_frac = float(mask_bool.sum() / bbox_area_px)\n",
    "\n",
    "    return {\n",
    "        \"area_frac\": area_frac,\n",
    "        \"cx\": cx, \"cy\": cy,\n",
    "        \"bbox_w\": bw, \"bbox_h\": bh,\n",
    "        \"bbox_area_frac\": bbox_area_frac,\n",
    "        \"bbox_xyxy\": [x0, y0, x1, y1],\n",
    "        \"fill_frac\": fill_frac,\n",
    "    }\n",
    "\n",
    "\n",
    "def bbox_xywh_from_mask(mask_bool: np.ndarray):\n",
    "    ys, xs = np.where(mask_bool)\n",
    "    if xs.size == 0:\n",
    "        return None\n",
    "    x0, x1 = int(xs.min()), int(xs.max())\n",
    "    y0, y1 = int(ys.min()), int(ys.max())\n",
    "    return [x0, y0, int(x1 - x0 + 1), int(y1 - y0 + 1)]\n",
    "\n",
    "\n",
    "# ---------- OpenCV-free min_mask_region_area replacement ----------\n",
    "def _remove_small_islands(mask: np.ndarray, min_area: int) -> np.ndarray:\n",
    "    if min_area <= 0:\n",
    "        return mask\n",
    "    lab, n = ndi.label(mask)\n",
    "    if n == 0:\n",
    "        return mask\n",
    "    sizes = ndi.sum(mask, lab, index=np.arange(1, n + 1))\n",
    "    keep = np.zeros(n + 1, dtype=bool)\n",
    "    keep[1:] = sizes >= min_area\n",
    "    return keep[lab]\n",
    "\n",
    "\n",
    "def _fill_small_holes(mask: np.ndarray, min_area: int) -> np.ndarray:\n",
    "    if min_area <= 0:\n",
    "        return mask\n",
    "    inv = ~mask\n",
    "    lab, n = ndi.label(inv)\n",
    "    if n == 0:\n",
    "        return mask\n",
    "\n",
    "    border = np.zeros_like(inv, dtype=bool)\n",
    "    border[0, :] = border[-1, :] = True\n",
    "    border[:, 0] = border[:, -1] = True\n",
    "    border_labels = np.unique(lab[border])\n",
    "\n",
    "    hole_labels = np.setdiff1d(np.arange(1, n + 1), border_labels, assume_unique=False)\n",
    "    if hole_labels.size == 0:\n",
    "        return mask\n",
    "\n",
    "    hole_sizes = ndi.sum(inv, lab, index=hole_labels)\n",
    "    small_holes = hole_labels[hole_sizes < min_area]\n",
    "    if small_holes.size == 0:\n",
    "        return mask\n",
    "\n",
    "    filled = mask.copy()\n",
    "    for hl in small_holes:\n",
    "        filled[lab == hl] = True\n",
    "    return filled\n",
    "\n",
    "\n",
    "def filter_mask_like_sam(mask: np.ndarray, min_area: int) -> np.ndarray:\n",
    "    mask = mask.astype(bool)\n",
    "    if min_area <= 0:\n",
    "        return mask\n",
    "    mask = _fill_small_holes(mask, min_area)\n",
    "    mask = _remove_small_islands(mask, min_area)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def iou(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    inter = np.logical_and(a, b).sum()\n",
    "    if inter == 0:\n",
    "        return 0.0\n",
    "    union = np.logical_or(a, b).sum()\n",
    "    return float(inter / max(1, union))\n",
    "\n",
    "\n",
    "def overlay_contours(img_rgb: np.ndarray, masks: np.ndarray, scores: np.ndarray, out_path: str, top_k=10):\n",
    "    if masks.size == 0:\n",
    "        Image.fromarray(img_rgb).save(out_path)\n",
    "        return\n",
    "    k = int(min(top_k, masks.shape[0]))\n",
    "    order = np.argsort(-scores)[:k]\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.axis(\"off\")\n",
    "    for rank, idx in enumerate(order, start=1):\n",
    "        plt.contour(masks[idx].astype(float), levels=[0.5], linewidths=2)\n",
    "        plt.text(10, 20 * rank, f\"mask {int(idx)} score={scores[idx]:.3f}\",\n",
    "                 color=\"white\", bbox=dict(facecolor=\"black\", alpha=0.5, pad=2))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def panoptic_viz(img_rgb: np.ndarray, label_map: np.ndarray, out_path: str, alpha=0.45, seed=0):\n",
    "    H, W, _ = img_rgb.shape\n",
    "    out = img_rgb.astype(np.float32).copy()\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    ids = np.unique(label_map)\n",
    "    ids = ids[ids >= 0]\n",
    "    colors = {int(i): rng.integers(0, 255, size=(3,), dtype=np.uint8) for i in ids}\n",
    "\n",
    "    overlay = img_rgb.copy()\n",
    "    for i in ids:\n",
    "        m = (label_map == i)\n",
    "        overlay[m] = colors[int(i)]\n",
    "\n",
    "    blended = (1 - alpha) * out + alpha * overlay.astype(np.float32)\n",
    "    blended = np.clip(blended, 0, 255).astype(np.uint8)\n",
    "    Image.fromarray(blended).save(out_path)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# RUN\n",
    "# =========================\n",
    "os.makedirs(OUT_ROOT, exist_ok=True)\n",
    "out_masks_dir = os.path.join(OUT_ROOT, \"masks_npz\")\n",
    "out_meta_dir  = os.path.join(OUT_ROOT, \"meta\")\n",
    "out_png_dir   = os.path.join(OUT_ROOT, \"mask_png\")\n",
    "out_viz_dir   = os.path.join(OUT_ROOT, \"viz\")\n",
    "\n",
    "for d in [out_masks_dir, out_meta_dir, out_png_dir, out_viz_dir]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"device:\", device)\n",
    "\n",
    "if not os.path.isfile(CHECKPOINT):\n",
    "    raise FileNotFoundError(f\"Checkpoint not found: {CHECKPOINT}\")\n",
    "\n",
    "sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT).to(device)\n",
    "sam.eval()\n",
    "\n",
    "# Predictor = lets us compute image encoder features once per image (for mask embeddings)\n",
    "predictor = SamPredictor(sam)\n",
    "\n",
    "# IMPORTANT: keep min_mask_region_area=0 to avoid cv2 import\n",
    "mask_generator = SamAutomaticMaskGenerator(\n",
    "    model=sam,\n",
    "    points_per_side=POINTS_PER_SIDE,\n",
    "    pred_iou_thresh=PRED_IOU_THRESH,\n",
    "    stability_score_thresh=STABILITY_SCORE_THRESH,\n",
    "    box_nms_thresh=BOX_NMS_THRESH,\n",
    "    crop_n_layers=CROP_N_LAYERS,\n",
    "    crop_overlap_ratio=CROP_OVERLAP_RATIO,\n",
    "    crop_n_points_downscale_factor=CROP_N_POINTS_DOWNSCALE,\n",
    "    min_mask_region_area=0,\n",
    ")\n",
    "\n",
    "paths = sorted(glob.glob(os.path.join(IN_DIR, \"*\")))\n",
    "if MAX_IMAGES != -1:\n",
    "    paths = paths[:MAX_IMAGES]\n",
    "\n",
    "for p in tqdm(paths, desc=\"AMG-prod\"):\n",
    "    name = os.path.splitext(os.path.basename(p))[0]\n",
    "    img_rgb = load_image_rgb(p)\n",
    "    H, W, _ = img_rgb.shape\n",
    "\n",
    "    # 1) Generate proposals\n",
    "    amg = mask_generator.generate(img_rgb)\n",
    "\n",
    "    # 2) Compute image embedding once (optional but powerful)\n",
    "    if SAVE_MASK_EMB:\n",
    "        predictor.set_image(img_rgb)\n",
    "        feat = predictor.get_image_embedding()  # (1,C,hf,wf), vit_b -> usually C=256, hf=wf=64\n",
    "        hf, wf = feat.shape[-2], feat.shape[-1]\n",
    "    else:\n",
    "        feat, hf, wf = None, None, None\n",
    "\n",
    "    candidates = []\n",
    "    for orig_i, m in enumerate(amg):\n",
    "        seg = m[\"segmentation\"].astype(bool)\n",
    "        if MIN_MASK_REGION_AREA > 0:\n",
    "            seg = filter_mask_like_sam(seg, MIN_MASK_REGION_AREA)\n",
    "\n",
    "        area_px = int(seg.sum())\n",
    "        if area_px == 0:\n",
    "            continue\n",
    "\n",
    "        pred_iou = float(m.get(\"predicted_iou\", 0.0))\n",
    "        stab = float(m.get(\"stability_score\", 0.0))\n",
    "        score = pred_iou * stab\n",
    "\n",
    "        st = mask_stats(seg)\n",
    "        if st is None:\n",
    "            continue\n",
    "\n",
    "        # per-mask embedding from SAM image encoder\n",
    "        emb = None\n",
    "        if SAVE_MASK_EMB:\n",
    "            mask_t = torch.from_numpy(seg[None, None].astype(np.float32)).to(device)\n",
    "            mask_small = F.interpolate(mask_t, size=(hf, wf), mode=\"nearest\")\n",
    "            denom = mask_small.sum(dim=(2, 3)) + 1e-6\n",
    "            emb_t = (feat * mask_small).sum(dim=(2, 3)) / denom  # (1,C)\n",
    "            emb = emb_t.squeeze(0).detach().cpu().to(torch.float16).numpy()  # (C,)\n",
    "\n",
    "        candidates.append({\n",
    "            \"orig_amg_index\": int(orig_i),\n",
    "            \"seg\": seg,\n",
    "            \"score\": float(score),\n",
    "            \"predicted_iou\": pred_iou,\n",
    "            \"stability_score\": stab,\n",
    "            \"area_px\": area_px,\n",
    "            \"bbox_xywh\": bbox_xywh_from_mask(seg),\n",
    "            \"stats\": st,\n",
    "            \"emb\": emb,\n",
    "        })\n",
    "\n",
    "    # 3) Sort and deduplicate (greedy IoU)\n",
    "    candidates.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    kept = []\n",
    "    for cand in candidates:\n",
    "        if len(kept) >= MAX_KEEP:\n",
    "            break\n",
    "        ok = True\n",
    "        for prev in kept:\n",
    "            if iou(cand[\"seg\"], prev[\"seg\"]) >= DEDUP_IOU_THRESH:\n",
    "                ok = False\n",
    "                break\n",
    "        if ok:\n",
    "            kept.append(cand)\n",
    "\n",
    "    # 4) Build final arrays\n",
    "    N = len(kept)\n",
    "    if N == 0:\n",
    "        masks = np.zeros((0, H, W), dtype=np.bool_)\n",
    "        scores = np.zeros((0,), dtype=np.float32)\n",
    "        embs = None\n",
    "        label_map = -np.ones((H, W), dtype=np.int32)\n",
    "        meta_masks = []\n",
    "    else:\n",
    "        masks = np.stack([k[\"seg\"] for k in kept], axis=0).astype(np.bool_)\n",
    "        scores = np.asarray([k[\"score\"] for k in kept], dtype=np.float32)\n",
    "\n",
    "        if SAVE_MASK_EMB:\n",
    "            embs = np.stack([k[\"emb\"] for k in kept], axis=0)  # (N,C) float16\n",
    "        else:\n",
    "            embs = None\n",
    "\n",
    "        # Non-overlapping label map: assign pixels to best mask first\n",
    "        label_map = -np.ones((H, W), dtype=np.int32)\n",
    "        occupied = np.zeros((H, W), dtype=bool)\n",
    "        order = np.argsort(-scores)\n",
    "        for new_id in order:\n",
    "            pix = masks[new_id] & (~occupied)\n",
    "            if pix.sum() == 0:\n",
    "                continue\n",
    "            label_map[pix] = int(new_id)\n",
    "            occupied[pix] = True\n",
    "\n",
    "        # Metadata\n",
    "        meta_masks = []\n",
    "        for new_id, k in enumerate(kept):\n",
    "            st = dict(k[\"stats\"])\n",
    "            st.update({\n",
    "                \"mask_index\": int(new_id),\n",
    "                \"orig_amg_index\": int(k[\"orig_amg_index\"]),\n",
    "                \"score\": float(k[\"score\"]),\n",
    "                \"predicted_iou\": float(k[\"predicted_iou\"]),\n",
    "                \"stability_score\": float(k[\"stability_score\"]),\n",
    "                \"area_px\": int(k[\"area_px\"]),\n",
    "                \"bbox_xywh\": k[\"bbox_xywh\"],\n",
    "            })\n",
    "            meta_masks.append(st)\n",
    "\n",
    "    # 5) Save compressed masks (+ embeddings)\n",
    "    packed = np.packbits(masks.reshape(masks.shape[0], -1), axis=1) if masks.shape[0] > 0 else np.zeros((0, 0), dtype=np.uint8)\n",
    "    np.savez_compressed(\n",
    "        os.path.join(out_masks_dir, f\"{name}.npz\"),\n",
    "        packed=packed,\n",
    "        shape=np.array(masks.shape, dtype=np.int32),\n",
    "        scores=scores,\n",
    "        label_map=label_map,\n",
    "        emb=embs,\n",
    "    )\n",
    "\n",
    "    with open(os.path.join(out_meta_dir, f\"{name}.json\"), \"w\") as f:\n",
    "        json.dump({\n",
    "            \"image\": p,\n",
    "            \"device\": device,\n",
    "            \"num_masks\": int(masks.shape[0]),\n",
    "            \"amg_params\": {\n",
    "                \"points_per_side\": POINTS_PER_SIDE,\n",
    "                \"crop_n_layers\": CROP_N_LAYERS,\n",
    "                \"crop_overlap_ratio\": CROP_OVERLAP_RATIO,\n",
    "                \"crop_n_points_downscale_factor\": CROP_N_POINTS_DOWNSCALE,\n",
    "                \"pred_iou_thresh\": PRED_IOU_THRESH,\n",
    "                \"stability_score_thresh\": STABILITY_SCORE_THRESH,\n",
    "                \"box_nms_thresh\": BOX_NMS_THRESH,\n",
    "                \"min_mask_region_area_post\": MIN_MASK_REGION_AREA,\n",
    "                \"dedup_iou_thresh\": DEDUP_IOU_THRESH,\n",
    "                \"max_keep\": MAX_KEEP,\n",
    "            },\n",
    "            \"masks\": meta_masks,\n",
    "        }, f, indent=2)\n",
    "\n",
    "    # 6) PNG exports for debugging\n",
    "    if masks.shape[0] > 0:\n",
    "        order = np.argsort(-scores)[:min(TOP_K_PNG, len(scores))]\n",
    "        for rank, idx in enumerate(order, start=1):\n",
    "            msk = (masks[idx].astype(np.uint8) * 255)\n",
    "            Image.fromarray(msk).save(os.path.join(out_png_dir, f\"{name}_mask{idx:04d}_rank{rank}_score{scores[idx]:.3f}.png\"))\n",
    "\n",
    "    overlay_contours(img_rgb, masks, scores, os.path.join(out_viz_dir, f\"{name}_contours.png\"), top_k=OVERLAY_TOP_K)\n",
    "    panoptic_viz(img_rgb, label_map, os.path.join(out_viz_dir, f\"{name}_panoptic.png\"), alpha=0.45, seed=0)\n",
    "\n",
    "print(f\"[DONE] outputs at: {OUT_ROOT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f680f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab3875a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec 21 15:12:10 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 565.57.01              Driver Version: 565.57.01      CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A30                     On  |   00000000:21:00.0 Off |                    0 |\n",
      "| N/A   36C    P0             31W /  165W |   21782MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A    185656      C   python                                        266MiB |\n",
      "|    0   N/A  N/A   1331534      C   ...z/conda_envs/pytorch_env/bin/python        402MiB |\n",
      "|    0   N/A  N/A   1439657      C   ...PyTorch_Env_2.0/packages/bin/python      20294MiB |\n",
      "|    0   N/A  N/A   2603535      C   python                                        290MiB |\n",
      "|    0   N/A  N/A   3690214      C   ...z/conda_envs/pytorch_env/bin/python        402MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3affbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array([[True, False, True, True], [True, False, True, True]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7a221d7-09fd-46b2-bac8-fb27fc487534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d11726ae-0e52-4bc5-8fb0-7865abad5a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "730e889b-eeec-4537-92fa-308ec4c995f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = torch.from_numpy(test[None].astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6bae90d-458c-4c8c-b2f3-51004f4ed117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 4])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4431a2e-9b34-4b99-b8e3-a6feca6f6624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 1., 1.],\n",
       "         [1., 0., 1., 1.]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04b2aa6-8f69-45ac-a6f2-d81cf82f39b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
